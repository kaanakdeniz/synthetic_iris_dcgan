{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport glob\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom ast import literal_eval\nfrom IPython import display\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.config.run_functions_eagerly(True)\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:05.128627Z","iopub.execute_input":"2022-02-10T22:43:05.129258Z","iopub.status.idle":"2022-02-10T22:43:10.257023Z","shell.execute_reply.started":"2022-02-10T22:43:05.129132Z","shell.execute_reply":"2022-02-10T22:43:10.256106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_iris_rectangle(image_dir, points, resize = False, size = (256, 256)):\n  image = cv2.imread(image_dir)\n  x,y,w,h = cv2.boundingRect(points)\n  margin = 1\n  crop = image[y-margin:y+h+margin,x-margin:x+w+margin]\n  if resize:\n    crop = cv2.resize(crop, size)\n  return crop\n\ndef save_image(img, dir):\n  cv2.imwrite(dir, img)\n\ndef convert_string_to_np_array(value):\n  ptsStr = literal_eval(value)\n  return np.array(ptsStr, np.int32)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.260915Z","iopub.execute_input":"2022-02-10T22:43:10.261362Z","iopub.status.idle":"2022-02-10T22:43:10.272839Z","shell.execute_reply.started":"2022-02-10T22:43:10.261324Z","shell.execute_reply":"2022-02-10T22:43:10.272158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(df, data_dir, output_dir):\n  print(f'Number of images: {len(df)}')\n  os.mkdir(output_dir)\n  for _, row in df.iterrows():\n    try:\n      file = os.path.join(data_dir, str(row[\"identity\"]), row[\"file\"])\n      dest = os.path.join(output_dir, row[\"file\"])\n      points = convert_string_to_np_array(row[\"outerPts\"])\n      iris = extract_iris_rectangle(file, points)\n      save_image(iris, dest)\n    except Exception as e:\n      continue\n  print(f'Number of processed images: {len(glob.glob(output_dir+\"/*\"))}')","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.277223Z","iopub.execute_input":"2022-02-10T22:43:10.279449Z","iopub.status.idle":"2022-02-10T22:43:10.288005Z","shell.execute_reply.started":"2022-02-10T22:43:10.279405Z","shell.execute_reply":"2022-02-10T22:43:10.287181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(datapath, image_size, batch_size):\n  dataset = keras.preprocessing.image_dataset_from_directory(datapath, label_mode=None, image_size=image_size, batch_size=batch_size, color_mode='rgb')\n  dataset = dataset.shuffle(len(dataset))\n  dataset = dataset.map(lambda x: (x - 127.5) / 127.5)\n  return dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.290285Z","iopub.execute_input":"2022-02-10T22:43:10.290824Z","iopub.status.idle":"2022-02-10T22:43:10.297819Z","shell.execute_reply.started":"2022-02-10T22:43:10.290788Z","shell.execute_reply":"2022-02-10T22:43:10.296510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GAN():\n    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)    \n\n    def __init__(self, latent_dim, input_shape, batch_size, l_rate):\n        self.latent_dim = latent_dim\n        self.input_shape = input_shape\n        self.batch_size = batch_size\n        self.l_rate = l_rate\n        self.d_losses = []\n        self.g_losses = []        \n        self.generator_optimizer = tf.keras.optimizers.Adam(l_rate)\n        self.discriminator_optimizer = tf.keras.optimizers.Adam(l_rate)\n        self.generator = self.make_generator_model()\n        self.discriminator = self.make_discriminator_model()\n    \n    def make_generator_model(self):\n        model = tf.keras.Sequential()\n        model.add(layers.Dense(8*8*512, use_bias=False, input_shape=(self.latent_dim,)))\n        model.add(layers.Reshape((8, 8, 512)))\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n        \n        model.add(layers.Conv2DTranspose(128, (4, 4), strides=(1, 1), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh'))\n\n        return model\n    \n    def test_generator(self):\n        noise = tf.random.normal([1, self.latent_dim])\n        generated_image = self.generator(noise, training=False)\n        plt.imshow(np.array(generated_image[0] * 127.5 + 127.5).astype(np.uint8))\n\n    def make_discriminator_model(self):\n        model = tf.keras.Sequential()\n        model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=self.input_shape))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n        \n        model.add(layers.Conv2D(128, (4, 4), strides=(1, 1), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same'))\n        model.add(layers.BatchNormalization())\n        model.add(layers.LeakyReLU())\n\n        model.add(layers.Flatten())\n        model.add(layers.Dropout(0.4))\n\n        model.add(layers.Dense(1, activation=\"sigmoid\"))\n\n        return model\n    \n    def test_discriminator(self):\n        noise = tf.random.normal([1, self.latent_dim])\n        generated_image = self.generator(noise, training=False)\n        return self.discriminator(generated_image)\n        \n\n    def discriminator_loss(self, real_output, fake_output):\n        real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\n        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n        total_loss = real_loss + fake_loss\n        return total_loss\n\n    def generator_loss(self, fake_output):\n        return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n    \n    def train(self, dataset, epochs):\n      for epoch in range(epochs):\n        start = time.time()\n\n        for image_batch in dataset:\n          self.train_step(image_batch)\n        display.clear_output(wait=True)\n        seed = tf.random.normal([16, self.latent_dim])\n        self.show_generated_images(epoch + 1,seed)\n\n        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n      display.clear_output(wait=True)   \n      img = self.show_generated_images(epochs, seed)\n    \n    @tf.function\n    def train_step(self, images):\n        noise = tf.random.normal([self.batch_size, self.latent_dim])\n\n        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n            generated_images = self.generator(noise, training=True)\n\n            real_output = self.discriminator(images, training=True)\n            fake_output = self.discriminator(generated_images, training=True)\n\n            gen_loss = self.generator_loss(fake_output)\n            disc_loss = self.discriminator_loss(real_output, fake_output)\n            d_l = disc_loss.numpy()\n            g_l = gen_loss.numpy()\n            self.d_losses.append(d_l)\n            self.g_losses.append(g_l)\n            print(f'\\rd_loss: {d_l}, g_loss: {g_l}',end=\"\")\n\n        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n\n        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n        \n    def show_generated_images(self, epoch, test_input):\n      predictions = self.generator(test_input, training=False)\n      fig = plt.figure(figsize=(4, 4))\n      for i in range(predictions.shape[0]):\n          plt.subplot(4, 4, i+1)\n          img = np.array(predictions[i] * 127.5 + 127.5).astype(np.uint8)\n          plt.imshow(img)\n          plt.axis('off')\n      print(f'\\r',end=\"\")  \n      plt.show()\n      return img\n        \n    def save_model(self, dir):\n        self.generator.save(dir)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.299296Z","iopub.execute_input":"2022-02-10T22:43:10.299694Z","iopub.status.idle":"2022-02-10T22:43:10.353985Z","shell.execute_reply.started":"2022-02-10T22:43:10.299661Z","shell.execute_reply":"2022-02-10T22:43:10.353074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_w = 128\nimage_h = 128\nimage_size = (image_w, image_h)\nchannels = 3\nimage_shape = [image_w, image_h, channels]\n\nlatent_dim = 128\nbatch_size = 16\nl_rate = 0.0001\nepochs = 300","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.358294Z","iopub.execute_input":"2022-02-10T22:43:10.358630Z","iopub.status.idle":"2022-02-10T22:43:10.366013Z","shell.execute_reply.started":"2022-02-10T22:43:10.358601Z","shell.execute_reply":"2022-02-10T22:43:10.365282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = \"../input/iris-data/data\"\ninfo_csv = \"../input/iris-data/data/info.csv\"\noutput_dir = \"../working/data\"\nmodels_dir = \"../working/models/\"","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.369873Z","iopub.execute_input":"2022-02-10T22:43:10.370312Z","iopub.status.idle":"2022-02-10T22:43:10.379532Z","shell.execute_reply.started":"2022-02-10T22:43:10.370280Z","shell.execute_reply":"2022-02-10T22:43:10.378408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k_fold = 5\ndf = pd.read_csv(info_csv, sep=\";\")\nif not os.path.exists(output_dir):\n    os.mkdir(output_dir)\nif not os.path.exists(models_dir):\n    os.mkdir(models_dir)\nfor i in range(k_fold,k_fold+1):\n    dest = os.path.join(output_dir, str(i))\n    if not os.path.exists(dest):\n        create_dataset(df[df[\"group\"] != i], data_dir, dest)\n    model = GAN(latent_dim, image_shape, batch_size, l_rate)\n    dataset = get_dataset(dest, image_size, batch_size)\n    model.train(dataset, epochs)\n    model.save_model(os.path.join(models_dir, str(i)+\".h5\"))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T22:43:10.382897Z","iopub.execute_input":"2022-02-10T22:43:10.383317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_model(os.path.join(models_dir, str(i)+\".h5\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip \"../working/models/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink \nFileLink(r'file.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}