{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split left and right eyes of MMU2 dataset\n",
    "persons = glob.glob(\"../dataset/mmu2/*\", recursive=True)\n",
    "\n",
    "leftPreExp= \"01\"\n",
    "rightPreExp = \"02\"\n",
    "for person in persons:\n",
    "  leftPath = os.path.join(person, \"left\")\n",
    "  rightPath = os.path.join(person, \"right\")\n",
    "  if not os.path.exists(leftPath):\n",
    "    os.makedirs(leftPath)\n",
    "  if not os.path.exists(rightPath):\n",
    "    os.makedirs(rightPath)\n",
    "  folderNum = int(person.split('\\\\')[-1])\n",
    "  personDir = \"0\"+str(folderNum) if folderNum < 10 else str(folderNum)\n",
    "  leftExp = personDir+leftPreExp\n",
    "  rightExp = personDir+rightPreExp\n",
    "  for image in glob.glob(person+\"/*.bmp\"):\n",
    "    image_name = image.split(\"\\\\\")[-1]\n",
    "    if image_name.startswith(leftExp):\n",
    "      shutil.copy2(image, os.path.join(leftPath, image_name))\n",
    "    if image_name.startswith(rightExp):\n",
    "      shutil.copy2(image, os.path.join(rightPath, image_name))\n",
    "    os.remove(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PAD Scores\n",
    "from pad.detector import PAD\n",
    "# imageFiles = glob.glob(\"./data/raw/**/*\")\n",
    "# scores = get_pad_scores(imageFiles, \"./pad/Model/D-NetPAD_Model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_in_scores(scores, file):\n",
    "  for record in scores:   \n",
    "      if(record[0] == file):\n",
    "        return record[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/raw\"\n",
    "info_csv = \"./data/raw/info.csv\"\n",
    "output_dir = \"./data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "numbers = rng.choice(398, size=398, replace=False) + 1\n",
    "fold_count = len(glob.glob(data_dir+\"/*/**\"))//5\n",
    "folds = []\n",
    "file_count=0\n",
    "identities = []\n",
    "for identity in numbers:\n",
    "  file_count += len(os.listdir(os.path.join(data_dir, str(identity))))\n",
    "  identities.append(identity)\n",
    "  if(file_count >= fold_count):\n",
    "    file_count = 0\n",
    "    folds.append({\"group\": len(folds) + 1, \"identities\": identities})\n",
    "    identities = []\n",
    "folds.append({\"group\": len(folds) + 1, \"identities\": identities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(identity):\n",
    "  return next((sub for sub in folds if identity in sub['identities']), None)[\"group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/raw/info.csv\", sep=\";\")\n",
    "df['identity'] = df.apply(lambda row: int(row[\"file\"].split(\"\\\\\")[0]), axis=1)\n",
    "df['file'] = df.apply(lambda row: row[\"file\"].split(\"\\\\\")[1], axis=1)\n",
    "df = df.sort_values(by=['identity'])\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:2]\n",
    "df= df[cols]\n",
    "df[\"filepath\"] = df.apply(lambda row: os.path.join(\"./data/raw\", str(row[\"identity\"]), row[\"file\"]), axis=1)\n",
    "df[\"pad_score\"] = df.apply(lambda row: find_in_scores(scores, row[\"filepath\"]), axis=1)\n",
    "df[\"group\"] = df.apply(lambda row: get_fold(row[\"identity\"]), axis=1)\n",
    "df.drop('filepath', axis=1, inplace=True)\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] +cols[:4]\n",
    "df= df[cols]\n",
    "df.to_csv(\"data.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/train.csv\", sep=\";\").to_dict(\"records\")\n",
    "df2 = pd.read_csv(\"./data/train.csv\", sep=\";\").to_dict(\"records\")\n",
    "\n",
    "lst = []\n",
    "for row1 in tqdm(df1, disable=True):\n",
    "  for row2 in tqdm(df2, disable=True):\n",
    "    if(row1[\"file\"] == row2[\"file\"]):\n",
    "      continue\n",
    "    folds = sorted([row1[\"group\"], row2[\"group\"]])\n",
    "    pairs = sorted([row1[\"file\"], row2[\"file\"]])  \n",
    "    pair_type = \"impostor\"\n",
    "    if row1[\"identity\"] == row2[\"identity\"]:\n",
    "      pair_type = \"genuine\"\n",
    "    dict = {'first': pairs[0], 'second': pairs[1], 'type': pair_type, 'group_first': folds[0], 'group_second': folds[1]}\n",
    "    lst.append(dict)\n",
    "df = pd.DataFrame(lst)\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.to_json(\"train_pairs.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef347fcf1aef20ac94a7eb30d18f8017b959c80d9ec041953859593fd5c1c2fe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
